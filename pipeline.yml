inspect:
  path : './data/inspect'
preprocess:
  prep_cfg:
    defaultprep: # This is the name of the preprocessing pipeline
      prepare:
        epoch_length : 5
        downsample : 500
        ica_method : 'fastica'
        skip_prep : False
        skip_reject : True
        normalization : True
      overwrite : True
  prep_list :
    - defaultprep
prep_inspection:
  path : './data/prep_inspection'
  overwrite : False
  checks:
    - 'epochs'
  prep_list :
    - defaultprep

features:
  feature_pipeline_cfg:
    features30@ROI@prep-defaultprep: #you set the name of the feature pipeline with the key
      prep_pipeline : 'defaultprep' # This is the name of the preprocessing pipeline previously defined (must exist in derivatives)
      downsample : 500
      prefilter :
        l_freq : 1
        h_freq : 30
      keep_channels : False
      feature_list: # To say which features actually compute rather than configure
        #- FooofFromAverage
        # - PowerSpectrum
        #- RelativeBandPower1
        #- RelativeBandPower2
        - FooofFromAverageROI # revisar no knee,  solo offset y slope
        # fooof revisar params de center (nuevo feature) freq, bandwith, relative power, en alpha extendido
        #- FooofFromAverageNoKnee
        #- PowerSpectrumROI
        - RelativeBandPower1ROI
        - dfaROI
        - lzivROI
        #- sampleEntropy
        - specEntROI
        #- spectralEntropytr
        #- appEntropy
        - hMobROI
        - hCompROI
        #- numZerocross
        - permEntROI
        - svdEntROI
        - higuchiROI
        - katzROI
        #- petrosianFd
        #- entropyMultiscale
        ##- PowerSpectrumAverage
        #- PowerSpectrumAverageROI
        # 15+12+27

    # another feature set pipeline as an example
    features25@prep-defaultprep:
      prep_pipeline : 'defaultprep' # This is the name of the preprocessing pipeline previously defined (must exist in derivatives)
      downsample : 500
      prefilter :
        l_freq : 1
        h_freq : 25
      keep_channels : False
      feature_list: # To say which features actually compute rather than configure
        - FooofFromAverage
        - PowerSpectrum
        - PowerSpectrumAverage
        - PowerSpectrumAverageROI
        - RelativeBandPower1
        - RelativeBandPower2
        - FooofFromAverageROI
        - PowerSpectrumROI
        - RelativeBandPower1ROI
  feature_pipeline_list: #which feature pipelines to run
    - features30@prep-defaultprep
    #- features25@prep-defaultprep
  feature_cfg: # You can configure different features for the same function but different args
    # The suffix will be the higher hierarchy name you put here
    PowerSpectrum:
      overwrite : False
      chain: # Chain is a list of either dict of defined functions (outputs not saved) or dict of defined features (output saved)
      # input of chain is assumed to be mne epochs unless it first item is directly a feature
      - function : spectrum_multitaper
        args:
          multitaper:
            adaptive : False
            low_bias : True
            normalization : 'full'
            verbose : 0
        
    PowerSpectrumAverage:
      overwrite : False
      chain:
        - feature : PowerSpectrum
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24
            axisname: 'epochs'
    PowerSpectrumAverageROI:
      overwrite : False
      chain:
        - feature : PowerSpectrumROI
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24
            axisname: 'epochs'
    RelativeBandPower1:
      overwrite : False
      chain :
        - feature : PowerSpectrum # this will save PowerSpectrum if not already saved
        - function: relative_bandpower
          args :
            bands:
              delta : [1,4]
              theta : [4,8]
              alpha : [8,13]
              beta  : [13,30]
              #pre_alpha : [5.5,8]
              #slow_theta : [4,5.5]
            multitaper : {}
            agg_fun : "eval%lambda x: agg_numpy(x,np.mean,axisname='epochs',max_numitem=24)" # You can set up max epochs by max_numitem obtained from prep_inspection
    RelativeBandPower2:
      overwrite : False
      chain :
        - feature : PowerSpectrum
        - function: relative_bandpower
          args :
            bands:
              alpha1 : [8.5, 10.5]
              alpha2 : [10.5, 12.5]
              beta1  : [12.5, 18.5]
              beta2  : [18.5, 21]
              beta3  : [21, 30]
            multitaper : {}
            agg_fun : "eval%lambda x: agg_numpy(x,np.mean,axisname='epochs',max_numitem=24)" # You can set up max epochs by max_numitem obtained from prep_inspection
    FooofFromAverage:
      overwrite : False
      chain:
        - feature : PowerSpectrum
        - function : fooof_from_average
          args :
            agg_fun : "eval%lambda x: agg_numpy(x,np.mean,axisname='epochs',max_numitem=24)" # You can set up max epochs by max_numitem obtained from prep_inspection
            internal_kwargs:
              FOOOF:
                aperiodic_mode : knee
              fit:
                freq_range : [2,35]
    FooofFromAverageNoKnee:
      overwrite : False
      chain:
        - feature : PowerSpectrum
        - function : fooof_from_average
          args :
            agg_fun : "eval%lambda x: agg_numpy(x,np.mean,axisname='epochs',max_numitem=24)" # You can set up max epochs by max_numitem obtained from prep_inspection
            internal_kwargs:
              FOOOF:
                aperiodic_mode : fixed
              fit:
                freq_range : [2,35]
    PowerSpectrumROIexample:
      overwrite : False
      chain :
        - feature : PowerSpectrum
        - function: roi_aggregator
          args :
            # function name must be roi_mapping, could define a dictionary inside and return the value from the key
            # if you want to reuse a roi mapping, you can define it in features.py and just call it here
            mapping : | 
              def roi_mapping(x):
                anterior = ["Fp1", "Fp2", "F3", "F4", "F7", "F8", "Fz"]
                central = ["T7", "T8", "C3", "C4", "Cz"]
                posterior = ["P3", "P4", "P7", "P8", "O1", "O2"]
                if x in anterior:
                  return 'anterior'
                elif x in central:
                  return 'central'
                elif x in posterior:
                  return 'posterior'
                else:
                  return 'none'
              # you have to put None in those channels that you dont want to include, Fp1,Fp2,Fz,Cz will be ignored in this example mapping
              #   if x[0] == 'F' and x[1].isdigit():
              #       return 'frontal'
              #   elif x[0] == 'C' and x[1].isdigit():
              #       return 'central'
              #   elif x[0]== 'P' and x[1].isdigit():
              #       return 'parietal'
              #   elif x[0]== 'O' and x[1].isdigit():
              #       return 'occipital'
              #   else:
              #       return 'none'
            numpyfun : "eval%np.mean"
            ignore : ['none']
    PowerSpectrumROI:
      overwrite : False
      chain :
        - feature : PowerSpectrum
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']
    FooofFromAverageROI:
      overwrite : False
      chain:
        - feature : PowerSpectrumROI
        - function : fooof_from_average
          args :
            agg_fun : "eval%lambda x: agg_numpy(x,np.mean,axisname='epochs',max_numitem=24)" # You can set up max epochs by max_numitem obtained from prep_inspection
            internal_kwargs:
              FOOOF:
                aperiodic_mode : fixed
              fit:
                freq_range : [2,35]
    RelativeBandPower1ROI:
      overwrite : False
      chain :
        - feature : PowerSpectrumROI # this will save PowerSpectrum if not already saved
        - function: relative_bandpower
          args :
            bands:
              delta : [1,4]
              theta : [4,8]
              alpha : [8,13]
              beta  : [13,30]
              pre_alpha : [5.5,8]
              slow_theta : [4,5.5]
            multitaper : {}
            agg_fun : "eval%lambda x: agg_numpy(x,np.mean,axisname='epochs',max_numitem=24)" # You can set up max epochs by max_numitem obtained from prep_inspection
    detrendedFluctuation:
      overwrite: False
      chain:
        - function: compute_detrendedFluctuation
          args:
            internal_kwargs:
              detrended_fluctuation : {}
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24
    dfaROI:
      overwrite: False
      chain:
        - feature: detrendedFluctuation
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']
    lzivComplexity:
      overwrite: False
      chain:
        - function: compute_lzivComplexity
          args:
            prefoo : "eval%lambda x: (x > np.median(x)).astype(int)"
            internal_kwargs:
              lziv_complexity :
                normalize: True
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24
    lzivROI:
      overwrite: False
      chain:
        - feature: lzivComplexity
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    sampleEntropy:
      overwrite: False
      chain:
        - function: compute_sampleEntropy
          args:
            internal_kwargs:
              sample_entropy :
                order : 2
                metric : chebyshev
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24
    sampEntROI:
      overwrite: False
      chain:
        - feature: sampleEntropy
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    spectralEntropy:
      overwrite: False
      chain:
        - function: compute_spectralEntropy
          args:
            internal_kwargs:
              spectral_entropy :
                sf : eval%eeg.info['sfreq']
                method : 'welch'
                nperseg : eval%int(np.round(eeg.info['sfreq']/1))
                normalize : True
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    specEntROI:
      overwrite: False
      chain:
        - feature: spectralEntropy
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    spectralEntropytr:
      overwrite: False
      chain:
        - function: compute_spectralEntropy
          args:
            internal_kwargs:
              spectral_entropy :
                sf : eval%eeg.info['sfreq']
                method : 'welch'
                nperseg : eval%int(np.round(eeg.info['sfreq']/5))
                normalize : True
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    appEntropy:
      overwrite: False
      chain:
        - function: compute_appEntropy
          args:
            internal_kwargs:
              app_entropy :
                order : 2
                metric : chebyshev
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24
    appEntROI:
      overwrite: False
      chain:
        - feature: appEntropy
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    hjorthParams:
      overwrite: False
      chain:
        - function: compute_hjorthParams
          args:
            internal_kwargs:
              hjorth_params: {}

    hjorthMobility:
      overwrite: False
      chain:
        - feature: hjorthParams
        - function: extract_item
          args:
            fun: "eval%lambda x: x[0]"
            newtype: hjorthMobility
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    hMobROI:
      overwrite: False
      chain:
        - feature: hjorthMobility
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    hjorthComplexity:
      overwrite: False
      chain:
        - feature: hjorthParams
        - function: extract_item
          args:
            fun: "eval%lambda x: x[1]"
            newtype: hjorthComplexity
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24
    hCompROI:
      overwrite: False
      chain:
        - feature: hjorthComplexity
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    numZerocross:
      overwrite: False
      chain:
        - function: compute_numZerocross
          args:
            internal_kwargs:
              num_zerocross:
                normalize: True
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    zeroROI:
      overwrite: False
      chain:
        - feature: numZerocross
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    permEntropy:
      overwrite: False
      chain:
        - function: compute_permEntropy
          args:
            internal_kwargs:
              perm_entropy:
                order: 3
                delay: 1
                normalize: True
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    permEntROI:
      overwrite: False
      chain:
        - feature: permEntropy
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    svdEntropy:
      overwrite: False
      chain:
        - function: compute_svdEntropy
          args:
            internal_kwargs:
              svd_entropy:
                order: 3
                delay: 1
                normalize: True
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    svdEntROI:
      overwrite: False
      chain:
        - feature: svdEntropy
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    higuchiFd:
      overwrite: False
      chain:
        - function: compute_higuchiFd
          args:
            internal_kwargs:
              higuchi_fd:
                kmax: 10
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    higuchiROI:
      overwrite: False
      chain:
        - feature: higuchiFd
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    katzFd:
      overwrite: False
      chain:
        - function: compute_katzFd
          args:
            internal_kwargs:
              katz_fd: {}
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    katzROI:
      overwrite: False
      chain:
        - feature: katzFd
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    petrosianFd:
      overwrite: False
      chain:
        - function: compute_petrosianFd
          args:
            internal_kwargs:
              petrosian_fd: {}
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    petroROI:
      overwrite: False
      chain:
        - feature: petrosianFd
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']

    entropyMultiscale: #TODO: i think the aggregation wont work here because multiscale return a complex datatype, check this
      overwrite: False
      chain:
        - function: compute_entropyMultiscale
          args:
            internal_kwargs:
              entropy_multiscale:
                scale : "default"
                dimension : 3
                tolerance : "sd"
                method : "MSEn"
                show : False
        - function: extract_item
          args:
            fun: "eval%lambda x: x[0]"
            newtype: null
        - function: agg_numpy
          args:
            numpyfun: eval%np.mean
            max_numitem: 24

    multiEntROI:
      overwrite: False
      chain:
        - feature: entropyMultiscale
        - function: roi_aggregator
          args : # using the defaul mapping which was defined in features.py
            numpyfun : "eval%np.mean"
            ignore : ['none']


aggregate:
  path : './data/aggregate'
  filename : 'aggregate.csv'
  id_splitter : '/'
  feature_return:
    RelativeBandPower1: # Could be the original name or a post-processed name
      return_function : "eval%lambda x: x"
      file_suffix : RelativeBandPower1
    RelativeBandPower1ROI: # Could be the original name or a post-processed name
      return_function : "eval%lambda x: x"
      file_suffix : RelativeBandPower1ROI
    fooofSlopeNoKnee:
      return_function : "eval%lambda x: x.aperiodic_params_[0]"
      file_suffix : FooofFromAverageNoKnee
    fooofSlope:
      return_function : "eval%lambda x: x.aperiodic_params_[0]"
      file_suffix : FooofFromAverage
    fooofSlopeROI:
      return_function : "eval%lambda x: x.aperiodic_params_[0]"
      file_suffix : FooofFromAverageROI
    detrendedFluctuation: # no text
      return_function : "eval%lambda x: x"
      file_suffix : detrendedFluctuation
    lzivComplexity: # text
      return_function : "eval%lambda x: x"
      file_suffix : lzivComplexity
    sampleEntropy: # text
      return_function : "eval%lambda x: x"
      file_suffix : sampleEntropy
    spectralEntropy: # text
      return_function : "eval%lambda x: x"
      file_suffix : spectralEntropy
    spectralEntropytr: # text
      return_function : "eval%lambda x: x"
      file_suffix : spectralEntropytr
    appEntropy: # text
      return_function : "eval%lambda x: x"
      file_suffix : appEntropy
    hjorthMobility: # text
      return_function : "eval%lambda x: x"
      file_suffix : hjorthMobility
    hjorthComplexity: # text
      return_function : "eval%lambda x: x"
      file_suffix : hjorthComplexity
    numZerocross: # text
      return_function : "eval%lambda x: x"
      file_suffix : numZerocross
    permEntropy: # text
      return_function : "eval%lambda x: x"
      file_suffix : permEntropy
    svdEntropy  : # text
      return_function : "eval%lambda x: x"
      file_suffix : svdEntropy
    higuchiFd: # text
      return_function : "eval%lambda x: x"
      file_suffix : higuchiFd
    katzFd: # text
      return_function : "eval%lambda x: x"
      file_suffix : katzFd
    petrosianFd : # text
      return_function : "eval%lambda x: x"
      file_suffix : petrosianFd
    entropyMultiscale:
      return_function: "eval%lambda x: x[0]"
      file_suffix : entropyMultiscale
    PowerSpectrumAverage:
      return_function: "eval%lambda x: x"
      file_suffix : PowerSpectrumAverage
    PowerSpectrumAverageROI:
      return_function: "eval%lambda x: x"
      file_suffix : PowerSpectrumAverageROI

  aggregate_cfgs:
    FeaturesROI@30@prep-defaultprep:
      feature_folder : 'features30@prep-defaultprep'
      feature_list: # CHOOSE FEATURES WITH SAME DIMENSIONS, OTHERWISE THE DATAFRAME CANT BE MADE
        - fooofSlopeROI
        - RelativeBandPower1ROI # could be the original name or a post-processed name
        # - PowerSpectrumAverageROI
    FeaturesChannels@30@prep-defaultprep:
      feature_folder : 'features30@prep-defaultprep'
      feature_list: # CHOOSE FEATURES WITH SAME DIMENSIONS, OTHERWISE THE DATAFRAME CANT BE MADE
        - RelativeBandPower1 # could be the original name or a post-processed name
        - fooofSlope
        - fooofSlopeNoKnee
        - detrendedFluctuation
        - lzivComplexity
        #- sampleEntropy
        - spectralEntropy
        #- spectralEntropytr
        #- appEntropy
        - hjorthMobility
        - hjorthComplexity
        - numZerocross
        - permEntropy
        - svdEntropy
        - higuchiFd
        - katzFd
        - petrosianFd
        #- entropyMultiscale
        #- PowerSpectrumAverage

scalingAndFolding:
  aggregate_folders:
    - 'FeaturesROI@30@prep-defaultprep'
    - 'FeaturesChannels@30@prep-defaultprep'
  MAX_FEATURES: null
  path : './data/scalingAndFolding'
  random_state : 0
  targets :
    - 'age'
  dropsToOnlyFeatures: # the targets will be appended to this in the script
    - id
    - sex
    - group
    - dataset
    - subject
    - task
  stratifiedvars :
    - dataset
    #- group make it easier to balance for test purposes
    #- sex
  scalings : # dont use _ - in the name (bids-like)
    scalingCombat : # name of this particular scaling config
        method : 'reCombat'
        init:
          parametric : True
          model : 'elastic_net'
          config : 
            alpha : 0.00001
          n_jobs : 7
          verbose : True
        covars :
          - dataset
          - sex
          - age
          #- group # seems we are missing data in testing conditions
        batch : dataset # which should be the one we drop from covars for the design matrix X in combat
        rename : # sync to covars, otherwise design matrix inconsistencies will throw an error
          age : age_numerical
        categorical : # sync to covars, otherwise design matrix inconsistencies will throw an error
          - dataset
          #- group
          - sex
    scalingStandard:
      method : 'StandardScaler'
    # we should implement a none scaling...
    noScaling:
      method: 'noScaling'
  splits : # dont use _ - in the name (bids-like)
    folding:
      method : 'StratifiedKFold'
      num_folds: 5 # stratified by combination by default
    trainTestSplit:
      method : 'train_test_split'
      test_ratio : 0.3
      stratify : True # Based on combination, see script for meaning...
    all :
      method : 'all'
  visualizations:
    PCAviz:
      method : 'PCA'
      n_components : 2
      color_by : dataset
      colormap : 'viridis'
  featurewiz:
    init:
      corr_limit : 0.75
      feature_engg : ''
      category_encoders : ''
      dask_xgboost_flag : False
      nrows : null # Dont use None here
      verbose : 0

ml:
  path: './data/ml'
  models:
    automljar :
      method : AutoMLjar
      init :
        algorithms :
          - 'Baseline'
          - 'Linear'
          - 'Decision Tree'
          # - 'Random Forest'
          # - 'Extra Trees'
          - 'LightGBM'
          - 'Xgboost'
          - 'CatBoost'
          # - 'Neural Network'
          # - 'Nearest Neighbors'
        explain_level : 1
        ml_task : 'auto'
        mode : Explain
        eval_metric : 'rmse'
        validation_strategy : 
          validation_type : custom
        model_time_limit : 3600
        n_jobs : 1

    autogluon:
      method: AutoGluon
      init:
        problem_type: 'regression'
        eval_metric: 'root_mean_squared_error'
        verbosity: 2
        log_to_file: True
        sample_weight: null
        groups: null
      fit :
        tuning_data : null
        time_limit : null
        presets : null
        hyperparameters : null
        feature_metadata : 'infer'
        infer_limit : null 
        infer_limit_batch_size : null
        fit_weighted_ensemble : True
        fit_full_last_level_weighted_ensemble : True
        full_weighted_ensemble_additionally  : False
        dynamic_stacking : False
        calibrate_decision_threshold : False
        num_cpus : 10
        num_gpus : auto
        num_bag_folds : 0

eda:
  path: './data/eda'
  
  # ols
  category_vars:
    - dataset
    - sex
  desired_threshold: 0.05
  formula: "{feature} ~ C(group, Treatment(reference='HC')) + age + sex"

  # plot based on feature type (1st level)
  # define functions (or a map-dictionary)
  feature_categories:
      by_band :
        category_name : byband
        category_mapping: |
          def category_mapping(x):
            for b in ['pre_alpha','alpha','beta','gamma','delta','slow_theta','theta']:
                if b in x:
                    return b
            else:
                return 'NoBand'
        input_column_mapping : Feature
        color_map:
          pre_alpha : blue
          alpha : green
          beta : yellow
          gamma : orange
          delta : red
          slow_theta : magenta
          theta : brown
          NoBand : black
      by_ROI :
        category_name : band
        category_mapping: |
          def category_mapping(x):
            for b in ['pre_alpha','alpha','beta','gamma','delta','slow_theta','theta']:
                if b in x:
                    return b
            else:
                return 'NoBand'
        input_column_mapping : Feature
        color_map:
          pre_alpha : blue
          alpha : green
          beta : yellow
          gamma : orange
          delta : red
          slow_theta : magenta
          theta : brown
          NoBand : black
